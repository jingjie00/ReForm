{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a vast collection of plastic bottles in various shapes, sizes, and colors. Our inventory includes:\n",
      "\n",
      "1. Water bottles: 5000+ units in 1L, 1.5L, and 2L sizes.\n",
      "2. Juice bottles: 3000+ units in 500ml, 1L, and 1.5L sizes.\n",
      "3. Soda bottles: 2000+ units in 330ml, 500ml, and 1L sizes.\n",
      "4. Oil bottles: 1000+ units in 1L, 2L, and 5L sizes.\n",
      "5. Cosmetic bottles: 500+ units in 50ml, 100ml, and 200ml sizes.\n",
      "\n",
      "Please note that our inventory is constantly changing due to new shipments and sales. If you're looking for a specific type of bottle, I recommend checking our website or contacting our customer support team for the most up-to-date information.\n",
      "\n",
      "Would you like to know more about our products or place an order?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=\"0cc39982-4848-46ca-959b-ef7dcbbed829\",base_url=\"https://api.sambanova.ai/v1\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='Meta-Llama-3.1-8B-Instruct',\n",
    "    messages=[{\"role\":\"system\",\"content\":\"You are the chatbot for a website selling plastic container eg bottle. You need to reply people on this context. You may integrate news, and question given by user.\"},{\"role\":\"user\",\"content\":\"How many bottles there is\"}],\n",
    "    temperature =  0.1,\n",
    "    top_p = 0.1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using flask\n",
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    data = request.get_json()\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-8B-Instruct',\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are the chatbot for a website selling plastic container eg bottle. You need to reply people on this context. You may integrate news, and question given by user.\"},{\"role\":\"user\",\"content\":data['message']}],\n",
    "        temperature =  0.1,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "    return jsonify({\"response\": response.choices[0].message.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a custom model in our server using pytorch\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "class GPT2Chatbot:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "    def chat(self, message):\n",
    "        input_ids = self.tokenizer.encode(message, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=1000, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "        return self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "chatbot = GPT2Chatbot()\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    data = request.get_json()\n",
    "    response = chatbot.chat(data['message'])\n",
    "    return jsonify({\"response\": response})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phdwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
